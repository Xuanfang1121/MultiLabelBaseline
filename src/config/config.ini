[strings]
# Mode : train, test, serve
train_data_file = ./data/event/train_data_demo.txt
test_data_file = ./data/event/dev_data_demo.txt
# train_data_file = ./data/ITT/train_data.txt
# test_data_file = ./data/ITT/test_data.txt

#  pretrain model path
pretrain_model_path = D:/Spyder/pretrain_model/transformers_torch_tf/bert-base-chinese/
# pretrain_model_path = /opt/nlp/pretrain_model/bert-base-chinese/
# pretrain_model_path = /opt/nlp/pretrain_model/simbert-base-chinese

# model parameter
gpu_ids = -1
model_type = bert
# select pooler, cls, mean, first_last_mean
model_layer_type = mean
# model evaluate methods, abs_acc, roc_auc, score, min_error_num, f1
evaluate_type = f1
# save para
output_path = ./output/
label2id_file = lable2id.json
save_model_name = model.ckpt

[ints]
seed = 1
batch_size = 2
dev_batch_size = 2
epochs = 1
max_length = 256
pre_epoch_print_step = 10
improvement_epoch = 10

[floats]
lr = 1e-5
threshold = 0.5

